{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLdWx896Nqfi"
      },
      "source": [
        "# Python Boot Camp\n",
        "\n",
        "\n",
        "Welcome! üòÉüëã\n",
        "\n",
        "In this notebook, we will go through some basic image processing in Python, come across standard tasks required while setting up deep learning pipelines, and familiarize ourselves with popular packages such as `glob`, `tifffile`, `tqdm`, `imgaug` and more.\n",
        "\n",
        "We will be using sample images from the *MoNuSeg* dataset provided by [Kumar et al, 2018](https://ieeexplore.ieee.org/document/8880654). The data was publicly made available [here](https://monuseg.grand-challenge.org/) by the authors of the publication.\n",
        "\n",
        "This dataset shows Hematoxylin and Eosin (H&E) Stained Images showing nuclei in different shapes.\n",
        "\n",
        "\n",
        "***\n",
        "\n",
        "## Table of contents:\n",
        "\n",
        "0. Chapter - 0\n",
        "  * [Downloading Data from an External URL](#zeroth)\n",
        "1. Chapter - 1\n",
        "  * [Images as Arrays](#first)   \n",
        "  * [Image Channels](#second)\n",
        "  * [Image Data Types](#third)\n",
        "  * [Reshaping Images](#fourth)\n",
        "  * [Normalizing Images](#fifth)\n",
        "  * [Loading a Set of Images](#sixth)\n",
        "2. Chapter - 2\n",
        "  * [Cropping](#seventh)\n",
        "  * [Downsampling](#eighth)\n",
        "  * [Flipping](#ninth)\n",
        "3. Chapter - 3\n",
        "  * [Creating Batches](#tenth)\n",
        "  * [Convolutions](#eleventh)\n",
        "  * [Design your own filter](#twelvth)\n",
        "4. Optional\n",
        "  * [Data augmentation](#thirteenth)\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Downloading data from an external url <a class=\"anchor\" name=\"zeroth\"></a>"
      ],
      "metadata": {
        "id": "YXLb2nCPbrKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us first download the images from an external url.\n",
        "To do so, we need to import some commonly used dependencies."
      ],
      "metadata": {
        "id": "05w0fc4kRGNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import urllib.request, zipfile"
      ],
      "metadata": {
        "id": "qRNE24fiRgK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, below is a helper function to download the data from an external url specified by argument `zip_url` and save it to a local directory specified by argument `project_name`. Let's execute the function (No output expected yet!)."
      ],
      "metadata": {
        "id": "rzl9vpqrRnvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_data(zip_url, project_name):\n",
        "  zip_path = Path(project_name + '.zip')\n",
        "  if (zip_path.exists()):\n",
        "      print(\"Zip file was downloaded and extracted before!\")\n",
        "  else:\n",
        "      urllib.request.urlretrieve(zip_url, zip_path)\n",
        "      print(\"Downloaded data as {}\".format(zip_path))\n",
        "      with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "          zip_ref.extractall('./')\n",
        "      print(\"Unzipped data to {}\".format(Path(project_name)))\n"
      ],
      "metadata": {
        "id": "V2_wVP5JSuVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we call the function `extract_data` specifying desirable values of the arguments."
      ],
      "metadata": {
        "id": "mgPfXx5uaunF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_data(\n",
        "    zip_url='https://owncloud.mpi-cbg.de/index.php/s/xwYonC9LucjLsY6/download',\n",
        "    project_name = 'monuseg-2018',\n",
        ")"
      ],
      "metadata": {
        "id": "x4w80xg3RqyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf monuseg-2018 monuseg-2018.zip"
      ],
      "metadata": {
        "id": "BMZz8mD2ZNfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task**: Click on the `Files` directory (left panel) and check if some images exist within the `monuseg-2018` directory."
      ],
      "metadata": {
        "id": "_o9xf4rOYmb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task**: Can you programmatically count the number of images and masks present in the `download/images` directory (Replace <path> with actual value).\n",
        "\n",
        "*Hint*: Use `!ls -l <path> | wc -l`"
      ],
      "metadata": {
        "id": "z5hELmw-Y6zg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DivCmaa-klHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsZaRQmENqfl"
      },
      "source": [
        "## 1.1 Images as arrays <a class=\"anchor\" name=\"first\"></a>\n",
        "\n",
        "2D Images are often represented as numpy arrays of shape (`height`, `width`, `num_channels`).\n",
        "\n",
        "![RGB image as a numpy array](https://github.com/dlmbl/boot/assets/34229641/ce1ad3f3-dc34-46d1-b301-198768fbc369)\n",
        "\n",
        "<div style=\"text-align: right\"> Credit: <a href=\"https://e2eml.school/convert_rgb_to_grayscale.html\">Brandon Rohrer‚Äôs Blog</a></div>\n",
        "\n",
        "\n",
        "Multiple utilities/packages exist to read images from files in Python.\n",
        "For example, one can use `tifffile.imread` to read `*.tif` images. <br>Another good package is `skimage.io.imread`.\n",
        "\n",
        "\n",
        "If you look in the directory (`monuseg-2018/download`), you can see directories called `images` and `masks`.\n",
        "\n",
        "Let's load one image and visualize it using `matplotlib.pyplot.imshow`. <br>\n",
        "`matplotlib.pyplot.imshow` is the standard way to show images in jupyter notebooks!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Hiu_NTKDNqfm"
      },
      "outputs": [],
      "source": [
        "from tifffile import imread\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "img = imread('monuseg-2018/download/images/TCGA-2Z-A9J9-01A-01-TS1.tif')\n",
        "print(f\"Image `img` has type {type(img)}\") # variable type\n",
        "imshow(img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task**:\n",
        "Can you visualize the corresponding `mask` for the image above. <br>\n",
        "(*Hint*: Look for the same name within the `masks` directory.) <br>\n",
        "What does the mask show?\n",
        "\n"
      ],
      "metadata": {
        "id": "ziA15gsghk9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = # TODO\n",
        "print(f\"Mask `mask` has type {type(mask)}\") # variable type\n",
        "imshow(mask)"
      ],
      "metadata": {
        "id": "E7rYlzODkjQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYm4ALPqNqfm"
      },
      "source": [
        "## 1.2 Image channels <a class=\"anchor\" name=\"second\"></a>\n",
        "If the image is a `grayscale` image, then the number of channels is equal to $1$,\n",
        "in which case the array can also be of shape (height, width). <br>\n",
        "If the image is `RGB`, then the number of channels is $3$.\n",
        "with each channel encoding the red, green and blue components.\n",
        "\n",
        "\n",
        "**Task**: Is <code>img</code> RGB or grayscale ?\n",
        "\n",
        "*Hint*: <a href=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf\">numpy cheatsheet</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReBxkjScNqfm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVF9dq6sNqfn"
      },
      "source": [
        "## 1.3 Image data types <a class=\"anchor\" name=\"third\"></a>\n",
        "\n",
        "\n",
        "Images can be represented by a variety of data types. The following is a list of the most common datatypes:\n",
        "- `bool`: binary, 0 or 1\n",
        "- `uint8`: unsigned integers, 0 to 255 range\n",
        "- `float`: -1 to 1 or 0 to 1\n",
        "\n",
        "\n",
        "**Task**: What is the data type of <code> img</code>? What are the minimum and maximum intensity values?\n",
        "\n",
        "*Hint*: <a href=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf\">numpy cheatsheet</a></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpWGrTdFNqfn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "EsAEAgnuNqfo"
      },
      "source": [
        "## 1.4 Reshaping Images <a class=\"anchor\" name=\"fourth\"></a>\n",
        "\n",
        "`PyTorch`, `TensorFlow` and `JAX` are popular deep learning frameworks.\n",
        "<br> In `PyTorch` images are represented as (`num_channels`, `height`, `width`).\n",
        "\n",
        "But the image which we are working with has the `channel` as the last axis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIFGnC0pNqfn"
      },
      "source": [
        "**Task**: Reshape <code>img</code> such that its shape is <code>(num_channels, height, width)</code>\n",
        "\n",
        "*Hint*: <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.transpose.html\">numpy transpose</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9cb0P4uNqfo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "img_reshaped = ## TODO\n",
        "print(f\"After reshaping, image has shape {img_reshaped.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.5 Normalizing Images <a class=\"anchor\" name=\"fifth\"></a>"
      ],
      "metadata": {
        "id": "sk5g7xsTqRVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It often helps model training, if we provide image inputs to the model which are between [0,1] intensities. <br>\n",
        "One way of normalizing an image is to divide the intensity on each pixel by the maximum allowed intensity for the available data type.\n",
        "\n",
        "**Task**: Obtain an intensity normalized image using the idea above.\n"
      ],
      "metadata": {
        "id": "qv8i4iMClvi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(img):\n",
        "  ###\n",
        "  ### TODO: ADD CODE\n",
        "  ###\n",
        "  return"
      ],
      "metadata": {
        "id": "z6RtC7-cmZ0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task**: What is the data type of the normalized image. Has it changed from before? Why?"
      ],
      "metadata": {
        "id": "BtDyr993mj3_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "00ewbhJsmuoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10mlRnw6Nqfq"
      },
      "source": [
        "## 1.6 Loading a set of images <a class=\"anchor\" name=\"sixth\"></a>\n",
        "\n",
        "Given a set of images in a folder, we need to be able to easily find the pathnames and load them in. <br>\n",
        "`glob` is a standard package that provides a utility for finding all pathnames that match a given pattern.\n",
        "\n",
        "Here, our images have the `.tif` extension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6dNrWPcMNqfq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "\n",
        "img_dir = 'monuseg-2018/download/images/'\n",
        "img_filenames = sorted(glob(os.path.join(img_dir, '*.tif')))\n",
        "\n",
        "print(f\"Found:\")\n",
        "for img_filename in img_filenames:\n",
        "    print(f\"{img_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task**: Load the set of masks, by correctly specifying the value of the variable `mask_filenames`"
      ],
      "metadata": {
        "id": "VJItpWTsv6-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mask_dir = # TODO: fill value!!\n",
        "#mask_filenames = # TODO: fill value!!\n",
        "#for mask_filename in mask_filenames:\n",
        "#   print(f\"{mask_filename}\")"
      ],
      "metadata": {
        "id": "aQRMRUdIwGjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize some of the images and the corresponding mask, side by side. First let's provide a helper `visualize` function which takes two images as argument.\n"
      ],
      "metadata": {
        "id": "1ZW_25HYxNXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import subplot, figure, tight_layout, axis\n",
        "import numpy\n",
        "def visualize(im1, im2):\n",
        "  figure(figsize=(10, 10))\n",
        "  subplot(121)\n",
        "  imshow(im1)\n",
        "  axis('off')\n",
        "  subplot(122)\n",
        "  imshow(im2)\n",
        "  axis('off')\n",
        "  tight_layout()"
      ],
      "metadata": {
        "id": "crviml5_h1Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executing the cell below, would visualize a new random image and the corresponding segmentation mask, each time. This is because the variable `idx` gets a new value between $0$ and $14$ (there are $15$ images)."
      ],
      "metadata": {
        "id": "D9rmPALah524"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = numpy.random.randint(len(img_filenames))\n",
        "visualize(imread(img_filenames[idx]), imread(mask_filenames[idx]))"
      ],
      "metadata": {
        "id": "S3W1i611w0LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1oq8AvLNqfq"
      },
      "source": [
        "\n",
        "<hr>\n",
        "Great Job! üéä\n",
        "\n",
        "**Checkpoint 1**\n",
        "\n",
        "In the first chapter, we learnt about:\n",
        "\n",
        "<li> image data types</li>\n",
        "<li> reshaping images </li>\n",
        "<li> normalizing images </li>\n",
        "<li> Using <code>glob</code> to load a set of images\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bonus Task for Chapter 1**: Can you think of alternate approaches to intensity normalization? Any benefits of following one over the other?"
      ],
      "metadata": {
        "id": "VaC27gH6qvoX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0j9cPVZNqfp"
      },
      "source": [
        "## 2.1 Cropping <a class=\"anchor\" name=\"seventh\"></a>\n",
        "\n",
        "While training models, we usually feed in smaller crops extracted from the original images.\n",
        "To do so, we can rely on the powerful numpy [indexing](https://numpy.org/doc/stable/reference/arrays.indexing.html).\n",
        "\n",
        "For example, let's extract the top left corner from one of our images.\n",
        "\n",
        "In the cell below, the original image is visualized on the left and the cropped image is seen on the right."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = numpy.random.randint(len(img_filenames))\n",
        "img = imread(img_filenames[idx])\n",
        "cropped_img = img[0:512, 0:512, :]\n",
        "visualize(img, cropped_img)"
      ],
      "metadata": {
        "id": "M5EnhwqY4LfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task** : Visualize the bottom left portion of any  image"
      ],
      "metadata": {
        "id": "9N-Ouk8X5_IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# idx = numpy.random.randint(len(img_filenames))\n",
        "# img = imread(img_filenames[idx])\n",
        "# cropped_img = # TODO : fill correct value!!\n",
        "# visualize(img, cropped_img)"
      ],
      "metadata": {
        "id": "Q93RGn9F6HYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Downsampling  <a class=\"anchor\" name=\"eighth\"></a>\n",
        "\n",
        "For large images, sometimes we require that they are downsampled to fit in memory.\n",
        "\n",
        "Say if one wants to have every fourth pixel from the original image, one specifies `factor` = $4$, and one can run the following cell:"
      ],
      "metadata": {
        "id": "wtT1jE9z6nc_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_cGB9rtHNqfp"
      },
      "outputs": [],
      "source": [
        "# downsampling\n",
        "idx = numpy.random.randint(len(img_filenames))\n",
        "img = imread(img_filenames[idx])\n",
        "\n",
        "factor = 4\n",
        "downsampled_img = img[::factor, ::factor]\n",
        "visualize(img, downsampled_img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task**: Can you see that the image on the right lacks some detail on account of being downsampled.\n",
        "\n",
        "Try other values of the downsampling factors `factor`."
      ],
      "metadata": {
        "id": "TgGt-MsH8zS6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f3E0x-B8lCjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Flipping <a class=\"anchor\" name=\"ninth\"></a>\n",
        "\n",
        "Sometimes, one wishes to create new images from original data by performing transformations.\n",
        "\n",
        "One way to create a new image is by flipping an image about a given axis, which creates a mirror image!\n",
        "\n",
        "Run the following cell to visualize a vertically flipped image."
      ],
      "metadata": {
        "id": "zsz49ihL8Th8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = numpy.random.randint(len(img_filenames))\n",
        "img = imread(img_filenames[idx])\n",
        "vflipped_img = img[::-1, :, :]\n",
        "visualize(img, vflipped_img)"
      ],
      "metadata": {
        "id": "dIDe_CtU7du_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSiPGi_ONqfq"
      },
      "source": [
        "**Task** : Create a horizontally flipped image and visualize!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoNb2lmVNqfq"
      },
      "outputs": [],
      "source": [
        "#idx = numpy.random.randint(len(img_filenames))\n",
        "#img = imread(img_filenames[idx])\n",
        "#hflipped_img = ## TODO: fill correct value\n",
        "#visualize(img, hflipped_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYb-xZynNqft"
      },
      "source": [
        "<hr>\n",
        "Fantastic Work! üôè\n",
        "\n",
        "<h1>Checkpoint 2</h1>\n",
        "\n",
        "In the second chapter, we learnt about:\n",
        "\n",
        "<li> cropping images\n",
        "<li> downsampling images\n",
        "<li> flipping images\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bonus Task for Chapter 2**:\n",
        "\n",
        "Can you think of reasons why we need to crop images?\n",
        "Can't we feed in all the images at the original size to the model?"
      ],
      "metadata": {
        "id": "YAGg2OFYBcPo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I2JXykGNqfs"
      },
      "source": [
        "## 3.1 Creating Batches <a class=\"anchor\" name=\"tenth\"></a>\n",
        "\n",
        "In ML/DL, we often have to deal with very large datasets. It is sometimes not possible to process all the data at once (since all of it wouldn't fit in the memory), so it's useful to split the data into \"mini-batches\".\n",
        "\n",
        "Creating batches of data is also useful from the point of view of optimizing the model.\n",
        "\n",
        "Let us make our first batch of images, containing $B$ number of images.\n",
        "The shape of the batch will thus get an additional \"batch dimension\" at the first dimension, i.e. (batch_size, num_channels, height, width).\n",
        "\n",
        "**Task**: Make a batch of size $B=4$ by sampling 4 images randomly from the available images (this will be a 4D numpy array).\n",
        "<br> Here, you would also have to ensure that the second axis corresponds to the channel (use *numpy.transpose*) (See Task [1.4](#fourth)).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RII-zMJKNqft"
      },
      "outputs": [],
      "source": [
        "#`batch` should be a numpy array with shape (4, 3, 1000, 1000).\n",
        "\n",
        "# batch = # TODO\n",
        "# print(batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mmkLg6VNqft"
      },
      "source": [
        "## 3.2 Convolutions <a class=\"anchor\" name=\"eleventh\"></a>\n",
        "\n",
        "Convolutions are the elementary operations used in Convolutional Neural Networks (CNNs).\n",
        "\n",
        "Below is a visual of the pixel values in the output image (green) being computed from neighboring pixels in the input image (blue) by convolving it with a filter (gray) which goes over the input image in a specific fashion.\n",
        "\n",
        "![](https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_no_strides.gif)\n",
        "\n",
        "**Credit**: <a href=\"https://github.com/vdumoulin/conv_arithmetic\">Vincent Dumoulin, Francesco Visin</a>\n",
        "\n",
        "\n",
        "**Task** : Implement a function that performs a convolution of an image with a filter.\n",
        "\n",
        "<br> Assume that your image and filter are square (i.e. height = width) and that the filter has an odd height/width. You can assume arbitrary values in your filter for now.\n",
        "\n",
        "<br> Note that your output image will be smaller.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8csjog_NNqft"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def conv2d(img, filter):\n",
        "    assert filter.shape[0] == filter.shape[1]\n",
        "    assert filter.shape[0]%2 !=0\n",
        "\n",
        "    d = img.shape[0]  # height of original image\n",
        "    d_f = filter.shape[0]  # height of filter\n",
        "    # TODO\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task**: We noticed that the output image is smaller than the input image! <br>\n",
        "\n",
        "Can you come up with an analytical relationship regarding how much smaller the output image is vis a vis the input image? <br>\n",
        "Can you think of any strategy which ensures that the output image is the same size as the input image?"
      ],
      "metadata": {
        "id": "oxHeLcX5HHsU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hehYOlOdNqft"
      },
      "source": [
        "### 3.3 Design your own filter <a class=\"anchor\" name=\"twelvth\"></a>\n",
        "\n",
        "Let us try to understand what the values of the filter should be. <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm0B_x-f6RFD"
      },
      "source": [
        "The following is known as the Sobel filter:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "    1 & 2 & 1 \\\\\n",
        "    0 & 0 & 0 \\\\\n",
        "    -1 & -2 & -1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "**Task**: What pattern would produce the largest output when convolved with this filter? </b>\n",
        "\n",
        "**Task**: Apply the Sobel filter and check if it does what you previously guessed! </b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxyUxAkv6RFE"
      },
      "outputs": [],
      "source": [
        "filter = np.array([[1,2,1], [0, 0, 0], [-1, -2, -1]])\n",
        "idx = numpy.random.randint(len(img_filenames))\n",
        "img = imread(img_filenames[idx])\n",
        "output_img = conv2d(img[..., 0], filter)\n",
        "visualize(img[..., 0], output_img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task**: Say if we are interested in finding roundish bright or dark structures in our data, what would be a reasonable filter? Discuss?"
      ],
      "metadata": {
        "id": "1KKUunnY0_bP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF_C9mqX6RFF"
      },
      "source": [
        "\n",
        "\n",
        "<hr>\n",
        "Wow! ü§ü\n",
        "\n",
        "<h1>Checkpoint 3</h1>\n",
        "In the third chapter, we learnt about:\n",
        "<li> Creating batches </li>\n",
        "<li> Convolutions </li>\n",
        "<li> Designing your own filter</li>\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xtFQ9OgTNqfu"
      },
      "source": [
        "## (Optional) Data augmentation <a class=\"anchor\" name=\"thirteenth\"></a>\n",
        "\n",
        "In ML/DL, we're often limited by the size of our the training set. Usually acquiring clean image per noisy image (image restoration); segmentation masks per raw image (image segmentation) etc is an arduous task.\n",
        "\n",
        "How could we artificially increase our data to help the model generalize better?\n",
        "\n",
        "One trick is to make simple transformations to our data - this process is generally called \"data augmentation\".  \n",
        "\n",
        "`imgaug` is a Python library that provides a very extensive set of image augmentations. Let us import `imgaug` in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cgjViKCMNqfv"
      },
      "outputs": [],
      "source": [
        "from imgaug import augmenters as iaa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "0oWxp7QHNqfv"
      },
      "source": [
        "#### Applying one augmentation\n",
        "\n",
        "We can pick an augmentation from a list of available augmentations.\n",
        "\n",
        "For example, with affine transformations, we can specify the range of the rotation angle to betwen `(-45, 45)` degrees.\n",
        "\n",
        "In `imgaug`, the channel-axis is always expected to be the last axis and the batch - axis to be the first axis. <br> For that purpose, we artifically add a batch axis using `np.newaxis`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kabFDSz_Nqfv"
      },
      "outputs": [],
      "source": [
        "rotate = iaa.Affine(rotate=(-45, 45))\n",
        "idx = numpy.random.randint(len(img_filenames))\n",
        "img = imread(img_filenames[idx])\n",
        "img_aug = rotate(images=img[np.newaxis, ...])\n",
        "visualize(img, img_aug[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb5FO5BHNqfv"
      },
      "source": [
        "#### Applying multiple augmentations\n",
        "We can linearly combine multiple augmentations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LEFLVceJNqfv"
      },
      "outputs": [],
      "source": [
        "seq = iaa.Sequential([\n",
        "    iaa.AdditiveGaussianNoise(scale=(0, 30)),\n",
        "    iaa.pillike.FilterEdgeEnhanceMore(),\n",
        "    iaa.Crop(percent=(0., 0.2)),\n",
        "    rotate\n",
        "])\n",
        "img_aug = seq(images=img[np.newaxis, ...])\n",
        "visualize(img, img_aug[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "raOt8ddtNqfw"
      },
      "source": [
        "**Task**: Familiarize yourself with the different augmentations available through <code>imgaug</code>. <br>\n",
        "\n",
        "Refer to the <a href = \"https://github.com/aleju/imgaug\">examples</a> and the <a href=\"https://imgaug.readthedocs.io/en/latest/\">documentation</a>. <br>Try out and apply augmentations that you think are interesting."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task**: While augmenting images and segmentation masks, should they be augmented similarly or differently? Discuss."
      ],
      "metadata": {
        "id": "pVY66f1_5UTM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM8tIQm46539"
      },
      "source": [
        "<hr>\n",
        "\n",
        "Hurrah! üòÉ\n",
        "<h1>Checkpoint 4</h1>\n",
        "In the fourth chapter, we learnt about:\n",
        "<li> Using <code>imgaug</code> for augmenting images </li>\n",
        "<li> Putting together multiple augmentations using <code>iaa.Sequential</code></li>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i9e60vF4nzdE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}