{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OLdWx896Nqfi"
   },
   "source": [
    "# Python Boot Camp\n",
    "\n",
    "\n",
    "Welcome! üòÉüëã\n",
    "\n",
    "In this notebook, we will go through some basic image processing in Python, come across standard tasks required while setting up deep learning pipelines, and familiarize ourselves with popular packages such as `glob`, `tifffile`, `tqdm`, `albumenations` and more.\n",
    "\n",
    "We will be using sample images from the *MoNuSeg* dataset provided by [Kumar et al, 2018](https://ieeexplore.ieee.org/document/8880654). The data was publicly made available [here](https://monuseg.grand-challenge.org/) by the authors of the publication.\n",
    "\n",
    "This dataset shows Hematoxylin and Eosin (H&E) Stained Images showing nuclei in different shapes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YXLb2nCPbrKn"
   },
   "source": [
    "## Chapter 0: Downloading data from an external url"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "05w0fc4kRGNV"
   },
   "source": [
    "Let us first download the images from an external url.\n",
    "To do so, we need to import some commonly used dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRNE24fiRgK2"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import urllib.request, zipfile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rzl9vpqrRnvc"
   },
   "source": [
    "Here, below is a helper function to download the data from an external url specified by argument `zip_url` and save it to a local directory specified by argument `project_name`. Let's execute the function (No output expected yet!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2_wVP5JSuVU"
   },
   "outputs": [],
   "source": [
    "def extract_data(zip_url, project_name):\n",
    "    zip_path = Path(project_name + '.zip')\n",
    "    if (zip_path.exists()):\n",
    "        print(\"Zip file was downloaded and extracted before!\")\n",
    "    else:\n",
    "        urllib.request.urlretrieve(zip_url, zip_path)\n",
    "        print(\"Downloaded data as {}\".format(zip_path))\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('./')\n",
    "    print(\"Unzipped data to {}\".format(Path(project_name)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mgPfXx5uaunF"
   },
   "source": [
    "Now we call the function `extract_data` specifying desirable values of the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4w80xg3RqyA",
    "outputId": "73b8033c-fee7-4da3-b3a8-7798166a80f8"
   },
   "outputs": [],
   "source": [
    "extract_data(\n",
    "    zip_url='https://owncloud.mpi-cbg.de/index.php/s/xwYonC9LucjLsY6/download',\n",
    "    project_name = 'monuseg-2018',\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_o9xf4rOYmb8"
   },
   "source": [
    "### Task 0.1\n",
    "Click on the `Files` directory (left panel) and check if some images exist within the `monuseg-2018` directory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "z5hELmw-Y6zg"
   },
   "source": [
    "### Task 0.2\n",
    "Can you a bash command to programmatically count the number of images and masks present in the `download/images` directory.\n",
    "\n",
    "*Hint*: Use `!ls -l <path> | wc - l`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dsZaRQmENqfl"
   },
   "source": [
    "### Images as arrays <a class=\"anchor\" name=\"first\"></a>\n",
    "\n",
    "2D Images are often represented as numpy arrays of shape (`height`, `width`, `num_channels`).\n",
    "\n",
    "![RGB image as a np array](https://github.com/dlmbl/boot/assets/34229641/ce1ad3f3-dc34-46d1-b301-198768fbc369)\n",
    "\n",
    "<div style=\"text-align: right\"> Credit: <a href=\"https://e2eml.school/convert_rgb_to_grayscale.html\">Brandon Rohrer‚Äôs Blog</a></div>\n",
    "\n",
    "\n",
    "Multiple utilities/packages exist to read images from files in Python.\n",
    "For example, one can use `tifffile.imread` to read `*.tif` images. <br>Another good package is `skimage.io.imread`.\n",
    "\n",
    "\n",
    "If you look in the directory (`monuseg-2018/download`), you can see directories called `images` and `masks`.\n",
    "\n",
    "Let's load one image and visualize it using `matplotlib.pyplot.imshow`. <br>\n",
    "`matplotlib.pyplot.imshow` is the standard way to show images in jupyter notebooks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "Hiu_NTKDNqfm",
    "outputId": "369a3baf-7afc-4ab1-c66a-7539cff5d526",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tifffile import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = imread('monuseg-2018/download/images/TCGA-2Z-A9J9-01A-01-TS1.tif')\n",
    "print(f\"Image `img` has type {type(img)}\") # variable type\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ziA15gsghk9a"
   },
   "source": [
    "### Task 1.1\n",
    "Can you visualize the corresponding `mask` for the image above. <br>\n",
    "(*Hint*: Look for the same name within the `masks` directory.) <br>\n",
    "What does the mask show?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "mask = ... # TODO\n",
    "print(f\"Mask `mask` has type {type(mask)}\") # variable type\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MYm4ALPqNqfm"
   },
   "source": [
    "### Image channels\n",
    "If the image is a `grayscale` image, then the number of channels is equal to $1$,\n",
    "in which case the array can also be of shape (height, width). <br>\n",
    "If the image is `RGB`, then the number of channels is $3$.\n",
    "with each channel encoding the red, green and blue components."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MYm4ALPqNqfm"
   },
   "source": [
    "### Task 1.2\n",
    "Is <code>img</code> RGB or grayscale ? What about the mask?\n",
    "\n",
    "*Hint*: <a href=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/np_Python_Cheat_Sheet.pdf\">np cheatsheet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QVF9dq6sNqfn"
   },
   "source": [
    "### Image data types\n",
    "\n",
    "\n",
    "Images can be represented by a variety of data types. The following is a list of the most common datatypes:\n",
    "- `bool`: binary, 0 or 1\n",
    "- `uint8`: unsigned integers, 0 to 255 range\n",
    "- `float`: -1 to 1 or 0 to 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QVF9dq6sNqfn"
   },
   "source": [
    "### Task 1.3\n",
    "What is the data type of <code> img</code>? What are the minimum and maximum intensity values?\n",
    "\n",
    "*Hint*: <a href=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/np_Python_Cheat_Sheet.pdf\">np cheatsheet</a></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EsAEAgnuNqfo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reshaping Images\n",
    "\n",
    "`PyTorch`, `TensorFlow` and `JAX` are popular deep learning frameworks.\n",
    "<br> In `PyTorch` images are represented as (`num_channels`, `height`, `width`).\n",
    "\n",
    "But the image which we are working with has the `channel` as the last axis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mIFGnC0pNqfn"
   },
   "source": [
    "### Task 1.4\n",
    "Reshape <code>img</code> such that its shape is <code>(num_channels, height, width)</code>\n",
    "\n",
    "*Hint*: <a href=\"https://np.org/doc/stable/reference/generated/np.transpose.html\">np transpose</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9cb0P4uNqfo"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "import numpy as np\n",
    "img_reshaped = ... ## TODO\n",
    "print(f\"After reshaping, image has shape {img_reshaped.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qv8i4iMClvi2"
   },
   "source": [
    "### Normalizing Images\n",
    "\n",
    "It often helps model training, if we provide image inputs to the model which are between [0,1] intensities. <br>\n",
    "One way of normalizing an image is to divide the intensity on each pixel by the maximum allowed intensity for the available data type."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qv8i4iMClvi2"
   },
   "source": [
    "### Task 1.5\n",
    "Obtain an intensity normalized image using the idea above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6RtC7-cmZ0d"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "def normalize(img):\n",
    "    norm_img = ... # TODO\n",
    "    return norm_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BtDyr993mj3_"
   },
   "source": [
    "### Task 1.6\n",
    "What is the data type of the normalized image. Has it changed from before? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "10mlRnw6Nqfq"
   },
   "source": [
    "### Loading a set of images\n",
    "\n",
    "Given a set of images in a folder, we need to be able to easily find the pathnames and load them in. <br>\n",
    "`glob` is a standard package that provides a utility for finding all pathnames that match a given pattern.\n",
    "\n",
    "Here, our images have the `.tif` extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dNrWPcMNqfq",
    "outputId": "dc029d8d-e65a-455e-84e8-05480f20d28b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "img_dir = 'monuseg-2018/download/images/'\n",
    "img_filenames = sorted(glob(os.path.join(img_dir, '*.tif')))\n",
    "\n",
    "print(f\"Found:\")\n",
    "for img_filename in img_filenames:\n",
    "    print(f\"{img_filename}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VJItpWTsv6-E"
   },
   "source": [
    "### Task 1.7\n",
    "Load the set of masks, by correctly specifying the value of the variables `mask_dir` and `mask_filenames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQRMRUdIwGjb"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "mask_dir = ... # TODO: fill value!!\n",
    "mask_filenames = ... # TODO: fill value!!\n",
    "for mask_filename in mask_filenames:\n",
    "    print(f\"{mask_filename}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZW_25HYxNXg"
   },
   "source": [
    "Let's visualize some of the images and the corresponding mask, side by side. First let's provide a helper `visualize` function which takes two images as argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crviml5_h1Jd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize(im1, im2):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(im1)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(im2)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "D9rmPALah524"
   },
   "source": [
    "Executing the cell below, would visualize a new random image and the corresponding segmentation mask, each time. This is because the variable `idx` gets a new value between $0$ and $14$ (there are $15$ images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "S3W1i611w0LB",
    "outputId": "b86b8f08-28c5-429a-de90-05541abb5dfe"
   },
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(img_filenames))\n",
    "visualize(imread(img_filenames[idx]), imread(mask_filenames[idx]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "A1oq8AvLNqfq"
   },
   "source": [
    "## Checkpoint 1\n",
    "\n",
    "Great Job! üéä Please post in the chat when you reach this checkpoint.\n",
    "\n",
    "In the first chapter, we learned about:\n",
    "\n",
    "<li> image data types</li>\n",
    "<li> reshaping images </li>\n",
    "<li> normalizing images </li>\n",
    "<li> Using <code>glob</code> to load a set of images\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VaC27gH6qvoX"
   },
   "source": [
    "**Bonus Task for Chapter 1**: Can you think of alternate approaches to intensity normalization? Any benefits of following one over the other?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "b0j9cPVZNqfp"
   },
   "source": [
    "## Chapter 2\n",
    "### Cropping\n",
    "\n",
    "While training models, we usually feed in smaller crops extracted from the original images.\n",
    "To do so, we can rely on the powerful numpy [indexing](https://np.org/doc/stable/reference/arrays.indexing.html).\n",
    "\n",
    "For example, let's extract the top left corner from one of our images.\n",
    "\n",
    "In the cell below, the original image is visualized on the left and the cropped image is seen on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "M5EnhwqY4LfW",
    "outputId": "50bd702a-781a-43f8-d953-040455d771dd"
   },
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(img_filenames))\n",
    "img = imread(img_filenames[idx])\n",
    "cropped_img = img[0:512, 0:512, :]\n",
    "visualize(img, cropped_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9N-Ouk8X5_IK"
   },
   "source": [
    "### Task 2.1\n",
    "Visualize the bottom left portion of any  image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q93RGn9F6HYu"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "idx = np.random.randint(len(img_filenames))\n",
    "img = imread(img_filenames[idx])\n",
    "cropped_img = ... # TODO : fill correct value!!\n",
    "visualize(img, cropped_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wtT1jE9z6nc_"
   },
   "source": [
    "### Downsampling\n",
    "\n",
    "For large images, sometimes we require that they are downsampled to fit in memory.\n",
    "\n",
    "Say if one wants to have every fourth pixel from the original image, one specifies `factor` = $4$, and one can run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "_cGB9rtHNqfp",
    "outputId": "276e438b-5644-4cb4-d8cd-55bd056b5080",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# downsampling\n",
    "idx = np.random.randint(len(img_filenames))\n",
    "img = imread(img_filenames[idx])\n",
    "\n",
    "factor = 4\n",
    "downsampled_img = img[::factor, ::factor]\n",
    "visualize(img, downsampled_img)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TgGt-MsH8zS6"
   },
   "source": [
    "### Task\n",
    "Can you see that the image on the right lacks some detail on account of being downsampled.\n",
    "\n",
    "Try other values of the downsampling factors `factor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "factor = ...\n",
    "downsampled_img = img[::factor, ::factor]\n",
    "visualize(img, downsampled_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zsz49ihL8Th8"
   },
   "source": [
    "### Flipping\n",
    "\n",
    "Sometimes, one wishes to create new images from original data by performing transformations.\n",
    "\n",
    "One way to create a new image is by flipping an image about a given axis, which creates a mirror image!\n",
    "\n",
    "Run the following cell to visualize a vertically flipped image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "dIDe_CtU7du_",
    "outputId": "84110054-1d83-4afa-ca67-54c602356d2b"
   },
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(img_filenames))\n",
    "img = imread(img_filenames[idx])\n",
    "vflipped_img = img[::-1, :, :]\n",
    "visualize(img, vflipped_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uSiPGi_ONqfq"
   },
   "source": [
    "### Task 2.2\n",
    "Create a horizontally flipped image and visualize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GoNb2lmVNqfq"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "idx = np.random.randint(len(img_filenames))\n",
    "img = imread(img_filenames[idx])\n",
    "hflipped_img = ... ## TODO: fill correct value\n",
    "visualize(img, hflipped_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oYb-xZynNqft"
   },
   "source": [
    "<hr>\n",
    "Fantastic Work! üôè Please post on the course chat when you reach this checkpoint.\n",
    "\n",
    "## Checkpoint 2\n",
    "\n",
    "In the second chapter, we learnt about:\n",
    "\n",
    "<li> cropping images\n",
    "<li> downsampling images\n",
    "<li> flipping images\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YAGg2OFYBcPo"
   },
   "source": [
    "**Bonus Task for Chapter 2**\n",
    "\n",
    "Can you think of reasons why we need to crop images?\n",
    "Can't we feed in all the images at the original size to the model?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nl4Glo5rlVTd"
   },
   "source": [
    "1. To increase the amount of data i.e, have more training data and corresponding masks\n",
    "2. Also because often the training images come with different sizes and this creates an issue while `batching` the images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0I2JXykGNqfs"
   },
   "source": [
    "## Chapter 3\n",
    "### Batching\n",
    "\n",
    "In ML/DL, we often have to deal with very large datasets. It soon becomes inefficient to process all the data at once, so it's useful to split the data into \"mini-batches\" that we can process individually.\n",
    "\n",
    "So for purely reasons of computational cost, this is often useful.\n",
    "\n",
    "We will also see another reason for which batching can be useful - for instance when running gradient descent on non-convex landscapes.\n",
    "Here, computing the gradient on a subset of the data gives us an approximate/noisy gradient making it less likely for us to end up being stuck in local minima. This is what is referred to as \"stochastic gradient descent\".\n",
    "\n",
    "Let us make our first batch of images, containing $B$ number of images.\n",
    "The shape of the batch will thus get an additional \"batch dimension\" at the first dimension, i.e. (batch_size, num_channels, height, width)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0I2JXykGNqfs"
   },
   "source": [
    "### Task 3.1\n",
    "\n",
    "Make a batch of size $B=4$ by sampling 4 images randomly from the available images (this will be a 4D np array).\n",
    "<br> Here, you would also have to ensure that the second axis corresponds to the channel (use `np.transpose`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RII-zMJKNqft"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "#`batch` should be a np array with shape (4, 3, 1000, 1000).\n",
    "\n",
    "batch = ... # TODO\n",
    "print(f\"Batch of images has shape {batch.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5mmkLg6VNqft",
    "tags": []
   },
   "source": [
    "### Convolutions\n",
    "\n",
    "Convolutions are the elementary operations used in Convolutional Neural Networks (CNNs). <br> The images (and later, the feature maps) are convolved with multiple filters whose weights are learned. <br> \n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/1/19/2D_Convolution_Animation.gif)\n",
    "\n",
    "\n",
    "Please read this [section](https://en.wikipedia.org/wiki/Kernel_(image_processing)#Convolution) on convolutions to learn how to implement a your own convolution function!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5mmkLg6VNqft",
    "tags": []
   },
   "source": [
    "### Task 3.2\n",
    "Implement a function that performs a convolution of an image with a filter.\n",
    "<br> Assume that your image is square and that your filter is square and has an odd width. You can set arbitrary values in your filter for now.\n",
    "\n",
    "<br> Note that your output image will be smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8csjog_NNqft"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "def conv2d(img, kernel):\n",
    "    assert kernel.shape[0] == kernel.shape[1]\n",
    "    assert kernel.shape[0]%2 !=0\n",
    "\n",
    "    h, w = img.shape[0], img.shape[1] # Starting size of image\n",
    "    d_k = kernel.shape[0] # Size of kernel\n",
    "\n",
    "    h_new = ... # Calculate the new height of the array\n",
    "    w_new = ... # Calculate the new width of the array\n",
    "    output = np.zeros((h_new, w_new))\n",
    "\n",
    "    # TODO: add your code for filling output with the convolved image\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to check your function\n",
    "\n",
    "identity = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 0]\n",
    "])\n",
    "new_im = conv2d(img[..., 0], identity) \n",
    "assert np.all(new_im == img[1:-1, 1:-1, 0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oxHeLcX5HHsU"
   },
   "source": [
    "### Task 3.3\n",
    "\n",
    "We noticed that the output image is smaller than the input image! <br>\n",
    "\n",
    "Can you come up with an analytical relationship regarding how much smaller the output image is *vis-√†-vis* the input image? <br>\n",
    "Can you think of any strategy which ensures that the output image is the same size as the input image?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hehYOlOdNqft",
    "tags": []
   },
   "source": [
    "### Filters\n",
    "\n",
    "Let us try to understand what could the values of the filter be. <br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HTO25riRNqfu"
   },
   "source": [
    "The following is known as the Sobel filter:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    1 & 2 & 1 \\\\\n",
    "    0 & 0 & 0 \\\\\n",
    "    -1 & -2 & -1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### Task 3.4\n",
    "Apply the Sobel filter and describe what it does\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "id": "GPpfplaPNqfu",
    "outputId": "17e9186f-32bb-4120-81e5-9a579bccf7dc"
   },
   "outputs": [],
   "source": [
    "flter = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
    "output_img = conv2d(img[..., 0], flter)\n",
    "visualize(img[..., 0], output_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5\n",
    "\n",
    "What feature in this image do you think this filter is detecting?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wFEqJ_XLNqfu"
   },
   "source": [
    "\n",
    "\n",
    "<hr>\n",
    "Wow! ü§ü Post on the course chat when you reach this checkpoint!\n",
    "\n",
    "## Checkpoint 3\n",
    "In the third chapter, we learnt about:\n",
    "<li> Batching </li>\n",
    "<li> Convolutions </li>\n",
    "<li> Filters</li>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xtFQ9OgTNqfu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Chapter 4: (Optional) Data augmentation\n",
    "\n",
    "Having collected your hard earned data you want to make the most of it. In ML/DL, we're often limited by the size of our the training set. How could we artificially inflate our data to provide more input to our model and help it generalize better?\n",
    "\n",
    "One trick is to make simple transformations to our data such as rotating it or adding noise - this process is generally called \"data augmentation\" (DA) and is widely used in ML.  \n",
    "\n",
    "`albumentations` is a Python library that provides a very extensive set of image augmentations,\n",
    "and that seamlessly handles complex annotations like segmentation maps, bounding boxes or keypoints. Let us import `albumentations` and its dependency `cv2` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgjViKCMNqfv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0oWxp7QHNqfv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Applying one augmentation\n",
    "\n",
    "To use an augmentation, we can instantiate a transformation with a set of hyperparameters.\n",
    "With a rotation, for example, we can specify the range of the rotation angle to be `(-45, 45)` degrees, always applied, and have a constant border around the rotation.\n",
    "\n",
    "In `albumentations`, the channel-axis is always expected to be the last axis and may be skipped for grayscale images. It is\n",
    "also recommended to work with the `uint8` dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "kabFDSz_Nqfv",
    "outputId": "301b9675-088e-41b4-ead6-6a9cf235cc9f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rotate = A.Rotate(limit=45, always_apply=True, border_mode=cv2.BORDER_CONSTANT)\n",
    "idx = np.random.randint(len(img_filenames))\n",
    "img = imread(img_filenames[idx])\n",
    "img_aug = rotate(image=img)\n",
    "visualize(img, img_aug['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb5FO5BHNqfv"
   },
   "source": [
    "### Applying multiple augmentations\n",
    "We can compose multiple augmentations. Run this cell multiple times to see how the output changes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "LEFLVceJNqfv",
    "outputId": "05462b74-c285-470e-f9db-ac6668ad33d4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "augment = A.Compose([\n",
    "    A.RandomCrop(width=256, height=256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    rotate\n",
    "])\n",
    "img_aug = augment(image=img)\n",
    "visualize(img, img_aug['image'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "raOt8ddtNqfw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 4.1\n",
    "Familiarize yourself with the different augmentations available through `albumentations`.\n",
    "\n",
    "Refer to the [examples](https://albumentations.ai/docs/examples/),  [tutorial](https://albumentations.ai/docs/getting_started/mask_augmentation/) and the [documentation](https://albumentations.ai/docs/).\n",
    "\n",
    "Identify and apply augmentations that you think are interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59he5hWTNqfw"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pVY66f1_5UTM",
    "tags": []
   },
   "source": [
    "### Task 4.2\n",
    "While augmenting images and segmentation masks, should they be augmented similarly or differently? Discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59he5hWTNqfw"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nz4LLp0cNqfw"
   },
   "source": [
    "<hr>\n",
    "Hurrah! üòÉ\n",
    "\n",
    "## Checkpoint 4\n",
    "In the fourth chapter, we learnt about:\n",
    "<li> Using <code>albumentations</code> for augmenting images </li>\n",
    "<li> Putting together multiple augmentations using <code>A.Compose</code></li>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufIqfh4Ep5tY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
