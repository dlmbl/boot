{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a860798",
   "metadata": {},
   "source": [
    "# Python Boot Camp\n",
    "\n",
    "\n",
    "Welcome! üòÉüëã\n",
    "\n",
    "In this notebook, we will go through some basic image processing in Python, come across standard tasks required while setting up deep learning pipelines, and familiarize ourselves with popular packages such as `glob`, `tifffile`, `tqdm`, `albumenations` and more.\n",
    "We will learn about:\n",
    "- Loading images (This is important as images are the primary input to most deep learning models)\n",
    "- Normalizing images (This is important as it helps in faster convergence of models becuse it helps in reducing the scale of the input data and hence the scale of the gradients)\n",
    "- Cropping images (This is important as it helps in creating smaller images from the original images which is useful for training models in a memory efficient way)\n",
    "- Downsampling images (This is important as it helps in reducing the size of the images which is useful for training models in a memory efficient way)\n",
    "- Flipping images (This is important as it helps in creating new images from the original data which is useful for training models in a memory efficient way)\n",
    "- Batching images (As we train in a SGD manner, batching is important as it helps in training the model in a memory efficient way and smoothens the optimization process)\n",
    "- Convolutions (This is important as it is the primary operation in Convolutional Neural Networks)\n",
    "- Data Augmentation (This is important as it helps in artificially increasing the size of the training data which is useful for training models in a memory efficient way)\n",
    "\n",
    "\n",
    "We will be using sample images from the *MoNuSeg* dataset provided by [Kumar et al, 2018](https://ieeexplore.ieee.org/document/8880654). The data was publicly made available [here](https://monuseg.grand-challenge.org/) by the authors of the publication.\n",
    "\n",
    "This dataset shows Hematoxylin and Eosin (H&E) Stained Images showing nuclei in different shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eae40e",
   "metadata": {},
   "source": [
    "## Chapter 0: Downloading data from an external url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae570a55",
   "metadata": {},
   "source": [
    "Let us first download the images from an external url.\n",
    "To do so, we need to import some commonly used dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e3804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import urllib.request, zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825ad543",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Here, below is a helper function to download the data from an external url specified by argument `zip_url` and save it to a local directory specified by argument `project_name`. Let's execute the function (No output expected yet!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8737172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(zip_url, project_name):\n",
    "    zip_path = Path(project_name + \".zip\")\n",
    "    if zip_path.exists():\n",
    "        print(\"Zip file was downloaded and extracted before!\")\n",
    "    else:\n",
    "        urllib.request.urlretrieve(zip_url, zip_path)\n",
    "        print(\"Downloaded data as {}\".format(zip_path))\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"./\")\n",
    "    print(\"Unzipped data to {}\".format(Path(project_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe6d8a7",
   "metadata": {},
   "source": [
    "Now we call the function `extract_data` specifying desirable values of the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f2047",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_data(\n",
    "    zip_url=\"https://owncloud.mpi-cbg.de/index.php/s/xwYonC9LucjLsY6/download\",\n",
    "    project_name=\"monuseg-2018\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265819d3",
   "metadata": {},
   "source": [
    "### Task 0.1\n",
    "Click on the `Files` directory (left panel) and check if some images exist within the `monuseg-2018` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004d61ad",
   "metadata": {},
   "source": [
    "### Task 0.2\n",
    "Can you a bash command to programmatically count the number of images and masks present in the `download/images` directory.\n",
    "\n",
    "*Hint*: Use `!ls -l <path> | wc - l` (you can run any bash command in a jupyter notebook by prefixing it with `!`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c843897",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f18974",
   "metadata": {},
   "source": [
    "## Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e08b0",
   "metadata": {},
   "source": [
    "### Images as arrays <a class=\"anchor\" name=\"first\"></a>\n",
    "\n",
    "2D Images are often represented as numpy arrays of shape (`height`, `width`, `num_channels`).\n",
    "\n",
    "![RGB image as a np array](https://github.com/dlmbl/boot/assets/34229641/ce1ad3f3-dc34-46d1-b301-198768fbc369)\n",
    "\n",
    "<div style=\"text-align: right\"> Credit: <a href=\"https://e2eml.school/convert_rgb_to_grayscale.html\">Brandon Rohrer‚Äôs Blog</a></div>\n",
    "\n",
    "\n",
    "Multiple utilities/packages exist to read images from files in Python.\n",
    "For example, one can use `tifffile.imread` to read `*.tif` images. <br>Another good package is `skimage.io.imread`.\n",
    "\n",
    "\n",
    "If you look in the directory (`monuseg-2018/download`), you can see directories called `images` and `masks`.\n",
    "\n",
    "Let's load one image and visualize it using `matplotlib.pyplot.imshow`. <br>\n",
    "`matplotlib.pyplot.imshow` is the standard way to show images in jupyter notebooks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9abf62e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from tifffile import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = imread(\"monuseg-2018/download/images/TCGA-2Z-A9J9-01A-01-TS1.tif\")\n",
    "print(f\"Image `img` has type {type(img)}\")  # variable type\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfeca23",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 1.1\n",
    "Can you visualize the corresponding `mask` for the image above. <br>\n",
    "(*Hint*: Look for the same name within the `masks` directory.) <br>\n",
    "What does the mask show?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20ccbd3",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "mask = ...  # TODO\n",
    "print(f\"Mask `mask` has type {type(mask)}\")  # variable type\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8712346",
   "metadata": {},
   "source": [
    "### Image channels\n",
    "If the image is a `grayscale` image, then the number of channels is equal to $1$,\n",
    "in which case the array can also be of shape (height, width). <br>\n",
    "If the image is `RGB`, then the number of channels is $3$.\n",
    "with each channel encoding the red, green and blue components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e129759a",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 1.2\n",
    "Is <code>img</code> RGB or grayscale ? What about the mask?\n",
    "\n",
    "*Hint*: <a href=\"https://assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf\">np cheatsheet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d8edb",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e473c",
   "metadata": {},
   "source": [
    "### Image data types\n",
    "\n",
    "\n",
    "Images can be represented by a variety of data types. The following is a list of the most common datatypes:\n",
    "- `bool`: binary, 0 or 1\n",
    "- `uint8`: unsigned integers, 0 to 255 range\n",
    "- `float`: -1 to 1 or 0 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eefc61",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 1.3\n",
    "What is the data type of <code>img</code> and the <code>mask</code> ? What are the minimum and maximum intensity values?\n",
    "\n",
    "*Hint*: <a href=\"https://assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf\">np cheatsheet</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2a0429",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68437d47",
   "metadata": {},
   "source": [
    "### Reshaping Images\n",
    "\n",
    "`PyTorch`, `TensorFlow` and `JAX` are popular deep learning frameworks.\n",
    "<br> In `PyTorch` images are represented as (`num_channels`, `height`, `width`).\n",
    "\n",
    "But the image which we are working with has the `channel` as the last axis.\n",
    "Therefore, we need to reshape (by swapping) the image to the correct shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26098f6",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 1.4\n",
    "Reshape <code>img</code> such that its shape is <code>(num_channels, height, width)</code>\n",
    "\n",
    "*Hint*: <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.transpose.html\">np transpose</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ed5b7",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Before reshaping, image has shape {img.shape}\")\n",
    "img_reshaped = ...  ## TODO\n",
    "print(f\"After reshaping, image has shape {img_reshaped.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc502ad9",
   "metadata": {},
   "source": [
    "### Normalizing Images\n",
    "\n",
    "It often helps model training, if we provide image inputs to the model which are between [0,1] intensities. <br>\n",
    "This is because the gradients are more stable and the model converges faster. And the model is not biased towards any particular intensity values. <br>\n",
    "One way of normalizing an image is to divide the intensity on each pixel by the maximum allowed intensity for the available data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af483490",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 1.5\n",
    "Obtain an intensity normalized image using the idea above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20b97c",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "def normalize(img):\n",
    "    norm_img = ...  # TODO\n",
    "    return norm_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1363332",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 1.6\n",
    "What is the data type of the normalized image. Has it changed from before? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0836ae7c",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fcb8b4",
   "metadata": {},
   "source": [
    "### Loading a set of images\n",
    "\n",
    "Given a set of images in a folder, we need to be able to easily find the pathnames and load them in. <br>\n",
    "`glob` is a standard package that provides a utility for finding all pathnames that match a given pattern.\n",
    "\n",
    "Here, our images have the `.tif` extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb86e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "img_dir = \"monuseg-2018/download/images/\"\n",
    "img_filenames = sorted(glob(os.path.join(img_dir, \"*.tif\")))\n",
    "\n",
    "print(f\"Found:\")\n",
    "for img_filename in img_filenames:\n",
    "    print(f\"{img_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b96150",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 1.7\n",
    "Load the set of masks, by correctly specifying the value of the variables `mask_dir` and `mask_filenames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52ef9e",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "mask_dir = ...  # TODO: fill value!!\n",
    "mask_filenames = ...  # TODO: fill value!!\n",
    "for mask_filename in mask_filenames:\n",
    "    print(f\"{mask_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e656b627",
   "metadata": {},
   "source": [
    "Let's visualize some of the images and the corresponding mask, side by side. First let's provide a helper `visualize` function which takes two images as argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2d2722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize(im1, im2):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(im1)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(im2)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e502dca",
   "metadata": {},
   "source": [
    "Executing the cell below, would visualize a new random image and the corresponding segmentation mask, each time. This is because the variable `idx` gets a new value between $0$ and $14$ (there are $15$ images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5d0b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(img_filenames))\n",
    "visualize(imread(img_filenames[idx]), imread(mask_filenames[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b53419",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## Checkpoint 1\n",
    "\n",
    "Great Job! üéä Please post in the chat when you reach this checkpoint.\n",
    "\n",
    "In the first chapter, we learned about:\n",
    "\n",
    "<li> image data types</li>\n",
    "<li> reshaping images </li>\n",
    "<li> normalizing images </li>\n",
    "<li> Using <code>glob</code> to load a set of images\n",
    "\n",
    "These are important concepts to understand as they form the basis of most image processing pipelines because they are the basic data handling operations.\n",
    "\n",
    "<hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76aca56",
   "metadata": {},
   "source": [
    "**Bonus Task for Chapter 1**: Can you think of alternate approaches to intensity normalization? Any benefits of following one over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd431bd6",
   "metadata": {},
   "source": [
    "Another approach could be percentile normalization. This maps the min intensity to 0 and max intensity to 0. This is useful if there are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6614979d",
   "metadata": {},
   "source": [
    "## Chapter 2\n",
    "### Cropping\n",
    "\n",
    "While training models, we usually feed in smaller crops extracted from the original images.\n",
    "To do so, we can rely on the powerful numpy [indexing](https://numpy.org/doc/stable/user/basics.indexing.html).\n",
    "\n",
    "For example, let's extract the top left corner from one of our images.\n",
    "\n",
    "In the cell below, the original image is visualized on the left and the cropped image is seen on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d8a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(img_filenames))\n",
    "img = imread(img_filenames[idx])\n",
    "cropped_img = img[0:512, 0:512, :]\n",
    "visualize(img, cropped_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f64d18",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 2.1\n",
    "Visualize the bottom left portion of any  image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e11386",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "idx = np.random.randint(len(img_filenames))\n",
    "img = imread(img_filenames[idx])\n",
    "cropped_img = ...  # TODO : fill correct value!!\n",
    "visualize(img, cropped_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1796de98",
   "metadata": {},
   "source": [
    "### Downsampling\n",
    "\n",
    "For large images, sometimes we require that they are downsampled to fit in memory.\n",
    "\n",
    "Say if one wants to have every fourth pixel from the original image, one specifies `factor` = $4$, and one can run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e10b62f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# downsampling\n",
    "idx = np.random.randint(len(img_filenames))\n",
    "img = imread(img_filenames[idx])\n",
    "\n",
    "factor = 4\n",
    "downsampled_img = img[::factor, ::factor]\n",
    "print(f\"Original image shape: {img.shape}\")\n",
    "print(f\"Downsampled image shape: {downsampled_img.shape}\")\n",
    "\n",
    "# Let's visualize the original image and the downsampled image side by side\n",
    "visualize(img, downsampled_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e71390",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 2.2\n",
    "Can you see that the image on the right lacks some detail on account of being downsampled.\n",
    "\n",
    "Try other values of the downsampling factors `factor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954fc74",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "factor = ...\n",
    "downsampled_img = img[::factor, ::factor]\n",
    "visualize(img, downsampled_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b661743c",
   "metadata": {},
   "source": [
    "### Flipping\n",
    "\n",
    "Sometimes, one wishes to create new images from original data by performing transformations.\n",
    "\n",
    "One way to create a new image is by flipping an image about a given axis, which creates a mirror image!\n",
    "\n",
    "Run the following cell to visualize a vertically flipped image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4108662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(img_filenames))\n",
    "img = imread(img_filenames[idx])\n",
    "# Here the image dimensions are (height, width, num_channels), ::-1 means reverse the order of the elements in the array on the height axis\n",
    "vflipped_img = img[::-1, :, :]\n",
    "visualize(img, vflipped_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dcf522",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 2.3\n",
    "Create a horizontally flipped image and visualize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfd0f65",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "idx = np.random.randint(len(img_filenames))\n",
    "img = imread(img_filenames[idx])\n",
    "hflipped_img = ...  ## TODO: fill correct value\n",
    "visualize(img, hflipped_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06acc0f8",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<hr>\n",
    "Fantastic Work! üôè Please post on the course chat when you reach this checkpoint.\n",
    "\n",
    "## Checkpoint 2\n",
    "\n",
    "In the second chapter, we learnt about:\n",
    "\n",
    "<li> cropping images </li>\n",
    "<li> downsampling images </li>\n",
    "<li> flipping images </li>\n",
    "\n",
    "These operations are important as they help in creating new images from the original data.\n",
    "These are also ways of basic data augmentation which is useful for training models.\n",
    "\n",
    "<hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd102f",
   "metadata": {},
   "source": [
    "**Bonus Task for Chapter 2**\n",
    "\n",
    "Can you think of reasons why we need to crop images?\n",
    "Can't we feed in all the images at the original size to the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28f2bae",
   "metadata": {},
   "source": [
    "1. To increase the amount of data i.e, have more training data and corresponding masks\n",
    "2. Also because often the training images come with different sizes and this creates an issue while `batching` the images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba84e6",
   "metadata": {},
   "source": [
    "## Chapter 3\n",
    "### Batching\n",
    "\n",
    "In ML/DL, we often have to deal with very large datasets. It soon becomes inefficient to process all the data at once, so it's useful to split the data into \"mini-batches\" that we can process individually.\n",
    "\n",
    "So for purely reasons of computational cost, this is often useful.\n",
    "\n",
    "We will also see another reason for which batching can be useful - for instance when running gradient descent on non-convex landscapes.\n",
    "Here, computing the gradient on a subset of the data gives us an approximate/noisy gradient making it less likely for us to end up being stuck in local minima. This is what is referred to as \"stochastic gradient descent\".\n",
    "\n",
    "Let us make our first batch of images, containing $B$ number of images.\n",
    "The shape of the batch will thus get an additional \"batch dimension\" at the first dimension, i.e. (batch_size, num_channels, height, width)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c0bb1d",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 3.1\n",
    "\n",
    "Make a batch of size $B=4$ by sampling 4 images randomly from the available images (this will be a 4D np array).\n",
    "<br> Here, you would also have to ensure that the second axis corresponds to the channel (use `np.transpose`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5899658e",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "# `batch` should be a np array with shape (4, 3, 1000, 1000).\n",
    "\n",
    "batch = ...  # TODO\n",
    "print(f\"Batch of images has shape {batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b200e3",
   "metadata": {},
   "source": [
    "### Convolutions\n",
    "\n",
    "Convolutions are the elementary operations used in Convolutional Neural Networks (CNNs). <br> The images (and later, the feature maps) are convolved with multiple filters whose weights are learned. <br>\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/1/19/2D_Convolution_Animation.gif)\n",
    "\n",
    "\n",
    "Please read this [section](https://en.wikipedia.org/wiki/Kernel_(image_processing)#Convolution) on convolutions to learn how to implement a your own convolution function!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f586486",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 3.2\n",
    "Implement a function that performs a convolution of an image with a filter.\n",
    "<br> Assume that your image is square and that your filter is square and has an odd width. You can set arbitrary values in your filter for now.\n",
    "\n",
    "<br> Note that your output image will be smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7986f2",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "\n",
    "def conv2d(img, kernel):\n",
    "    assert kernel.shape[0] == kernel.shape[1]\n",
    "    assert kernel.shape[0] % 2 != 0\n",
    "\n",
    "    h, w = img.shape[0], img.shape[1]  # Starting size of image\n",
    "    d_k = kernel.shape[0]  # Size of kernel\n",
    "\n",
    "    h_new = h - d_k + 1  # Calculate the new height of the array\n",
    "    w_new = w - d_k + 1  # Calculate the new width of the array\n",
    "    output = np.zeros((h_new, w_new))\n",
    "\n",
    "    # TODO: add your code for filling output with the convolved image\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7843907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to check your function\n",
    "\n",
    "identity = np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]])\n",
    "new_im = conv2d(img[..., 0], identity)\n",
    "# Lets print the original image and the convolved image\n",
    "print(img[..., 0].shape)\n",
    "print(new_im.shape)\n",
    "\n",
    "#Lets visualize the original image and the convolved image and the filter\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(131)\n",
    "plt.imshow(img[..., 0])\n",
    "plt.title(\"Original Image\")\n",
    "plt.subplot(132)\n",
    "plt.imshow(identity)\n",
    "plt.title(\"Kernel\")\n",
    "plt.subplot(133)\n",
    "plt.imshow(new_im)\n",
    "plt.title(\"Convolved Image\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1536d7cb",
   "metadata": {},
   "source": [
    "**Bonus: Try differnt (arbitary?) filters and see how the output changes! (You can find some [here] https://en.wikipedia.org/wiki/Kernel_(image_processing)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d5fa97",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 3.3\n",
    "\n",
    "We noticed that the output image is smaller than the input image! <br>\n",
    "\n",
    "Can you come up with an analytical relationship regarding how much smaller the output image is *vis-√†-vis* the input image? <br>\n",
    "Can you think of any strategy which ensures that the output image is the same size as the input image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10f2f1",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da3766",
   "metadata": {},
   "source": [
    "### Filters\n",
    "\n",
    "Let us try to understand what could the values of the filter be. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abed709",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "The following is known as the Sobel filter:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    1 & 2 & 1 \\\\\n",
    "    0 & 0 & 0 \\\\\n",
    "    -1 & -2 & -1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### Task 3.4\n",
    "Apply the Sobel filter and describe what it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f2302",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "flter = ...  # TODO\n",
    "output_img = conv2d(img[..., 0], flter)\n",
    "visualize(img[..., 0], output_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89704501",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 3.5\n",
    "\n",
    "What feature in this image do you think this filter is detecting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5becbec",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6806c48a",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<hr>\n",
    "Wow! ü§ü Post on the course chat when you reach this checkpoint!\n",
    "\n",
    "## Checkpoint 3\n",
    "\n",
    "In the third chapter, we learnt about:\n",
    "\n",
    "<li> Batching (here we understood the importance of batching in training models) </li>\n",
    "<li> Convolutions (The primary operation in Convolutional Neural Networks) </li>\n",
    "<li> Filters (The weights that are learned in Convolutional Neural Networks) </li>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20516aa",
   "metadata": {},
   "source": [
    "## Chapter 4: (Optional) Data augmentation\n",
    "\n",
    "Having collected your hard earned data you want to make the most of it. In ML/DL, we're often limited by the size of our the training set. How could we artificially inflate our data to provide more input to our model and help it generalize better?\n",
    "\n",
    "One trick is to make simple transformations to our data such as rotating it or adding noise - this process is generally called \"data augmentation\" (DA) and is widely used in ML.\n",
    "\n",
    "`albumentations` is a Python library that provides a very extensive set of image augmentations,\n",
    "and that seamlessly handles complex annotations like segmentation maps, bounding boxes or keypoints. Let us import `albumentations` and its dependency `cv2` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e56f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bceda3a",
   "metadata": {},
   "source": [
    "### Applying one augmentation\n",
    "\n",
    "To use an augmentation, we can instantiate a transformation with a set of hyperparameters.\n",
    "With a rotation, for example, we can specify the range of the rotation angle to be `(-45, 45)` degrees, always applied, and have a constant border around the rotation.\n",
    "\n",
    "In `albumentations`, the channel-axis is always expected to be the last axis and may be skipped for grayscale images. It is\n",
    "also recommended to work with the `uint8` dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ac65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate = A.Rotate(limit=45, always_apply=True, border_mode=cv2.BORDER_CONSTANT)\n",
    "idx = np.random.randint(len(img_filenames))\n",
    "img = imread(img_filenames[idx])\n",
    "img_aug = rotate(image=img)\n",
    "visualize(img, img_aug[\"image\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb95402",
   "metadata": {},
   "source": [
    "### Applying multiple augmentations\n",
    "We can compose multiple augmentations. Run this cell multiple times to see how the output changes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a7c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = A.Compose(\n",
    "    [\n",
    "        A.RandomCrop(width=256, height=256),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        rotate,\n",
    "    ]\n",
    ")\n",
    "img_aug = augment(image=img)\n",
    "visualize(img, img_aug[\"image\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83616b5",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 4.1\n",
    "Familiarize yourself with the different augmentations available through `albumentations`.\n",
    "\n",
    "Refer to the [examples](https://albumentations.ai/docs/examples/),  [tutorial](https://albumentations.ai/docs/getting_started/mask_augmentation/) and the [documentation](https://albumentations.ai/docs/).\n",
    "\n",
    "Identify and apply augmentations that you think are interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e12791",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a89840",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 4.2\n",
    "While augmenting images and segmentation masks, should they be augmented similarly or differently? Discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e514b64",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a6c573",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<hr>\n",
    "Hurrah! üòÉ\n",
    "\n",
    "## Checkpoint 4\n",
    "\n",
    "In the fourth chapter, we learnt about:\n",
    "\n",
    "<li> Using <code>albumentations</code> for augmenting images </li>\n",
    "<li> Putting together multiple augmentations using <code>A.Compose</code></li>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c2d60",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Chapter 5: (Absolutely Optional) Advanced Plotting and Visualization\n",
    "\n",
    "Python's matplotlib is a powerful library for creating visualizations. \n",
    "It is also highly customizable and can be used to create complex plots.\n",
    "In deep learning, visualizing the data is important as it helps in understanding the data and the model better.\n",
    "Therefore, it is important to know how to create different types of plots using matplotlib with specific (useful) functions.\n",
    "\n",
    "### Colormap\n",
    "You can choose a specific colormap to visualize your images.\n",
    "Read more about colormaps [here](https://matplotlib.org/stable/tutorials/colors/colormaps.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dbf9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[...,0], cmap=\"magma\")  #Note that we are only showing the first channel of the image\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c72af54",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "### Colorbar\n",
    "Sometimes, you may want to add a colorbar to your image to show the intensity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9cbcb8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img[...,0], cmap=\"magma\")\n",
    "plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512aeb35",
   "metadata": {},
   "source": [
    "\n",
    "### Plotting Histograms\n",
    "- Let's see the histogram of the intensity values\n",
    "- <code>img</img> is an 8-bit image, so the intensity values range from 0 to 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0140daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "# bins indicate how may unique buclets you might want to put your values in and range is the min and max values in the image \n",
    "# Try different values for bins and range to see how the histogram changes\n",
    "plt.hist(img[...,0].ravel(), bins=255, range=(0.0, img[...,0].max()))\n",
    "plt.xlabel(\"Intensity Value\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f03e38",
   "metadata": {},
   "source": [
    "Often we might need to plot multiple images side by side.\n",
    "Let's plot the crop of the original image from different locations side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a07e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "ax[0, 0].imshow(img[0:512, 0:512, :], cmap=\"magma\")\n",
    "ax[0, 1].imshow(img[512:, 512:, :], cmap=\"magma\")\n",
    "ax[1, 0].imshow(img[512:, 0:512, :], cmap=\"magma\")\n",
    "ax[1, 1].imshow(img[0:512, 512:, :], cmap=\"magma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef785789",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 5.1\n",
    "With all that knowledge, let's plot the 4 crop of the image in a first row and their histograms in a second row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4996e14c",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d22e8",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<hr>\n",
    "Hurrah! üòÉ\n",
    "\n",
    "## Checkpoint 5\n",
    "\n",
    "Chapter 5 is a bonus chapter where we learnt about:\n",
    "\n",
    "<li> Using colormaps to visualize images </li>\n",
    "<li> Adding colorbars to images </li>\n",
    "<li> Plotting histograms </li>\n",
    "<li> Plotting multiple images side by side </li>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
